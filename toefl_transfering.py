import os
import json
from model import SenseVoiceSmall
from funasr.utils.postprocess_utils import rich_transcription_postprocess
#the file is to produce the listening.txt file
# å‡è®¾ä½ å·²ç»å®šä¹‰äº† VoiceTranscriptionPipeline ç±»ï¼ˆå¦‚ä¸Šï¼‰
import os
import librosa
import soundfile as sf
import numpy as np
from pathlib import Path
import tempfile
import shutil
import os
import sys

# å°è¯•å¯¼å…¥ä¾èµ–ï¼Œè‹¥ç¼ºå¤±ç»™å‡ºæç¤º

import torch


class VoiceTranscriptionPipeline:
    def __init__(self, model_dir="iic/SenseVoiceSmall", device="cuda:0"):
        self.model, self.kwargs = SenseVoiceSmall.from_pretrained(
            model=model_dir, device=device)
        self.model.eval()
        self.device = device

    def transcribe_audio(self, audio_path, language="auto", use_itn=False,
                         ban_emo_unk=False, output_timestamp=False):
        """åŸºç¡€çš„çŸ­éŸ³é¢‘è½¬å½•æ–¹æ³•"""
        res = self.model.inference(
            data_in=audio_path,
            language=language,
            use_itn=use_itn,
            ban_emo_unk=ban_emo_unk,
            output_timestamp=output_timestamp,
            **self.kwargs
        )
        text = rich_transcription_postprocess(res[0][0]["text"])
        if output_timestamp:
            return text, res[0][0]["timestamp"]
        return text

    def split_audio_file(self, audio_path, chunk_duration=60, overlap=2, output_dir=None):
        """
        å°†é•¿éŸ³é¢‘æ–‡ä»¶åˆ‡å‰²æˆå°æ–‡ä»¶
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = tempfile.mkdtemp(prefix="audio_chunks_")
        else:
            os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path, sr=16000, mono=True)
        total_duration = len(y) / sr
        
        # è®¡ç®—åˆ‡ç‰‡å‚æ•°
        chunk_samples = chunk_duration * sr
        overlap_samples = overlap * sr
        step_samples = chunk_samples - overlap_samples
        
        chunks_info = []
        base_name = Path(audio_path).stem
        
        for i, start in enumerate(range(0, len(y), step_samples)):
            end = min(start + chunk_samples, len(y))
            chunk = y[start:end]
            
            # è®¡ç®—æ—¶é—´ä¿¡æ¯
            start_time = start / sr
            end_time = end / sr
            
            # ä¿å­˜åˆ‡ç‰‡æ–‡ä»¶
            chunk_filename = f"{base_name}_chunk_{i:04d}.wav"
            chunk_path = os.path.join(output_dir, chunk_filename)
            sf.write(chunk_path, chunk, sr)
            
            chunks_info.append({
                'path': chunk_path,
                'index': i,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time
            })
            
            print(f"åˆ›å»ºåˆ‡ç‰‡ {i+1}: {start_time:.1f}s - {end_time:.1f}s ({chunk_path})")
            
            if end >= len(y):
                break
        
        print(f"éŸ³é¢‘åˆ‡å‰²å®Œæˆ: å…±{len(chunks_info)}ä¸ªåˆ‡ç‰‡, æ€»æ—¶é•¿{total_duration:.1f}ç§’")
        return chunks_info, output_dir

    def transcribe_long_audio_segmented(self, audio_path, chunk_duration=60, overlap=2, 
                                      language="auto", use_itn=True, output_timestamp=True,
                                      keep_chunks=False, output_dir=None):
        """
        åˆ†æ®µè½¬å½•é•¿éŸ³é¢‘æ–‡ä»¶
        """
        print(f"å¼€å§‹å¤„ç†é•¿éŸ³é¢‘: {audio_path}")
        
        # åˆ‡å‰²éŸ³é¢‘æ–‡ä»¶
        chunks_info, chunks_dir = self.split_audio_file(
            audio_path, chunk_duration, overlap, output_dir)
        
        all_results = []
        full_text = ""
        full_timestamps = []
        
        try:
            # åˆ†æ®µå¤„ç†æ¯ä¸ªåˆ‡ç‰‡
            for chunk_info in chunks_info:
                print(f"å¤„ç†åˆ‡ç‰‡ {chunk_info['index']+1}/{len(chunks_info)}: "
                      f"{chunk_info['start_time']:.1f}s - {chunk_info['end_time']:.1f}s")
                
                try:
                    # ç›´æ¥è½¬å½•ï¼Œä¸è¿›è¡Œé‡å å¤„ç†
                    if output_timestamp:
                        text, timestamps = self.transcribe_audio(
                            audio_path=chunk_info['path'],
                            language=language,
                            use_itn=use_itn,
                            output_timestamp=True
                        )
                        # è°ƒæ•´æ—¶é—´æˆ³
                        adjusted_timestamps = self._adjust_timestamps(
                            timestamps, chunk_info['start_time'])
                        full_timestamps.extend(adjusted_timestamps)
                    else:
                        text = self.transcribe_audio(
                            audio_path=chunk_info['path'],
                            language=language,
                            use_itn=use_itn,
                            output_timestamp=False
                        )
                    
                    # ç®€å•çš„æ–‡æœ¬æ‹¼æ¥ï¼Œä¸è¿›è¡Œå¤æ‚çš„é‡å å¤„ç†
                    processed_text = text
                    
                    chunk_result = {
                        'chunk_index': chunk_info['index'],
                        'start_time': chunk_info['start_time'],
                        'end_time': chunk_info['end_time'],
                        'text': text,
                        'processed_text': processed_text,
                        'file_path': chunk_info['path']
                    }
                    
                    all_results.append(chunk_result)
                    full_text += " " + processed_text if full_text else processed_text
                    
                    print(f"åˆ‡ç‰‡ {chunk_info['index']+1} å®Œæˆ: {text[:50]}...")
                    
                except Exception as e:
                    print(f"åˆ‡ç‰‡ {chunk_info['index']+1} å¤„ç†å¤±è´¥: {e}")
                    import traceback
                    print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    
                    # æ·»åŠ ä¸€ä¸ªç©ºç»“æœä»¥ä¿æŒé¡ºåº
                    all_results.append({
                        'chunk_index': chunk_info['index'],
                        'start_time': chunk_info['start_time'],
                        'end_time': chunk_info['end_time'],
                        'text': '',
                        'processed_text': '',
                        'file_path': chunk_info['path'],
                        'error': str(e)
                    })
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not keep_chunks:
                if output_dir is None:  # ä¸´æ—¶ç›®å½•
                    shutil.rmtree(chunks_dir)
                else:
                    for chunk_info in chunks_info:
                        if os.path.exists(chunk_info['path']):
                            os.remove(chunk_info['path'])
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            result = {
                'full_text': full_text.strip(),
                'chunk_results': all_results,
                'total_chunks': len(chunks_info),
                'audio_duration': chunks_info[-1]['end_time'] if chunks_info else 0
            }
            
            if output_timestamp:
                result['timestamps'] = full_timestamps
            
            print(f"é•¿éŸ³é¢‘å¤„ç†å®Œæˆ: å…±å¤„ç†{len(chunks_info)}ä¸ªåˆ‡ç‰‡")
            return result
            
        except Exception as e:
            print(f"é•¿éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            # ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not keep_chunks and output_dir is None:
                shutil.rmtree(chunks_dir, ignore_errors=True)
            raise e

    def _adjust_timestamps(self, timestamps, offset):
        """è°ƒæ•´æ—¶é—´æˆ³åç§»"""
        if not timestamps:
            return []
            
        adjusted = []
        for ts in timestamps:
            if isinstance(ts, dict):
                adjusted.append({
                    'start': ts['start'] + offset,
                    'end': ts['end'] + offset,
                    'text': ts['text']
                })
            elif isinstance(ts, (list, tuple)) and len(ts) >= 2:
                adjusted.append([ts[0] + offset, ts[1] + offset] + list(ts[2:]))
            else:
                # å¦‚æœæ—¶é—´æˆ³æ ¼å¼æœªçŸ¥ï¼Œç›´æ¥è¿”å›åŸæ ·
                adjusted.append(ts)
        return adjusted

    def transcribe_long_audio_simple(self, audio_path, chunk_duration=60, 
                                   language="auto", use_itn=True, output_dir=None):
        """
        ç®€åŒ–ç‰ˆæœ¬çš„é•¿éŸ³é¢‘è½¬å½•ï¼Œæ²¡æœ‰é‡å å¤„ç†
        """
        print(f"å¼€å§‹ç®€åŒ–å¤„ç†é•¿éŸ³é¢‘: {audio_path}")
        
        # åˆ‡å‰²éŸ³é¢‘æ–‡ä»¶ï¼ˆä¸é‡å ï¼‰
        chunks_info, chunks_dir = self.split_audio_file(
            audio_path, chunk_duration, overlap=0, output_dir=output_dir)
        
        all_texts = []
        
        try:
            for i, chunk_info in enumerate(chunks_info):
                print(f"å¤„ç†åˆ‡ç‰‡ {i+1}/{len(chunks_info)}")
                
                try:
                    text = self.transcribe_audio(
                        audio_path=chunk_info['path'],
                        language=language,
                        use_itn=use_itn,
                        output_timestamp=False
                    )
                    
                    all_texts.append(text)
                    print(f"åˆ‡ç‰‡ {i+1} å®Œæˆ: {text[:100]}...")
                    
                except Exception as e:
                    print(f"åˆ‡ç‰‡ {i+1} å¤„ç†å¤±è´¥: {e}")
                    all_texts.append("")
            
            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            full_text = " ".join(filter(None, all_texts))
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if output_dir is None:
                shutil.rmtree(chunks_dir)
            else:
                for chunk_info in chunks_info:
                    if os.path.exists(chunk_info['path']):
                        os.remove(chunk_info['path'])
            
            result = {
                'full_text': full_text,
                'total_chunks': len(chunks_info),
                'successful_chunks': len([t for t in all_texts if t])
            }
            
            print(f"ç®€åŒ–å¤„ç†å®Œæˆ: æˆåŠŸ{result['successful_chunks']}/{result['total_chunks']}ä¸ªåˆ‡ç‰‡")
            return result
            
        except Exception as e:
            print(f"ç®€åŒ–å¤„ç†å¤±è´¥: {e}")
            if output_dir is None:
                shutil.rmtree(chunks_dir, ignore_errors=True)
            raise e

    def save_transcription_result(self, result, output_path):
        """ä¿å­˜è½¬å½•ç»“æœåˆ°æ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("å®Œæ•´è½¬å½•æ–‡æœ¬:\n")
            f.write("=" * 50 + "\n")
            f.write(result.get('full_text', '') + "\n\n")
            
            if 'timestamps' in result:
                f.write("æ—¶é—´æˆ³ä¿¡æ¯:\n")
                f.write("=" * 50 + "\n")
                for ts in result['timestamps']:
                    if isinstance(ts, dict):
                        f.write(f"[{ts['start']:.1f}s - {ts['end']:.1f}s]: {ts['text']}\n")
                    else:
                        f.write(f"{ts}\n")
                f.write("\n")
            
            if 'chunk_results' in result:
                f.write("åˆ†æ®µè¯¦ç»†ä¿¡æ¯:\n")
                f.write("=" * 50 + "\n")
                for chunk in result['chunk_results']:
                    f.write(f"åˆ‡ç‰‡ {chunk['chunk_index']+1}: "
                           f"{chunk['start_time']:.1f}s - {chunk['end_time']:.1f}s\n")
                    f.write(f"åŸå§‹æ–‡æœ¬: {chunk['text']}\n")
                    if 'error' in chunk:
                        f.write(f"é”™è¯¯: {chunk['error']}\n")
                    f.write("-" * 30 + "\n")


def main():
    base_dir = "data/task2"
    tpo_folders = [f"TPO{i}" for i in range(55, 56)]  # TPO66 åˆ° TPO75

    # åˆå§‹åŒ–è½¬å†™å™¨
    pipeline = VoiceTranscriptionPipeline()

    for folder in tpo_folders:
        folder_path = os.path.join(base_dir, folder)
        if not os.path.isdir(folder_path):
            print(f"âš ï¸  è·³è¿‡ï¼ˆæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼‰: {folder}")
            continue

        # æŸ¥æ‰¾ audio.m4a æˆ– audio.mp3
        audio_path = None
        for ext in [".m4a", ".mp3"]:
            candidate = os.path.join(folder_path, f"audio{ext}")
            if os.path.isfile(candidate):
                audio_path = candidate
                break

        output_path = os.path.join(folder_path, "listening.txt")

        # å§‹ç»ˆè¦†ç›–å†™å…¥ listening.txt
        with open(output_path, "w", encoding="utf-8") as f_out:
            if not audio_path:
                msg = "[ERROR] æœªæ‰¾åˆ° audio.m4a æˆ– audio.mp3\n"
                print(f"âŒ {folder}: éŸ³é¢‘ç¼ºå¤±")
                f_out.write(msg)
                continue

            print(f"ğŸ”Š æ­£åœ¨å¤„ç†: {folder} ({os.path.basename(audio_path)})")
            
            try:
                # è·å–éŸ³é¢‘æ—¶é•¿
                duration = get_audio_duration(audio_path)
                print(f"    â±ï¸  éŸ³é¢‘æ—¶é•¿: {duration:.1f}ç§’ ({duration/60:.1f}åˆ†é’Ÿ)")
                
                # ä»¥3åˆ†é’Ÿï¼ˆ180ç§’ï¼‰ä¸ºåˆ†å‰²ç‚¹è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
                if duration <= 180:  # 3åˆ†é’ŸåŠä»¥ä¸‹ä½¿ç”¨ç›´æ¥è½¬å½•
                    print("    ğŸ¯ ä½¿ç”¨ç›´æ¥è½¬å½•æ¨¡å¼ï¼ˆâ‰¤3åˆ†é’Ÿï¼‰")
                    transcription = pipeline.transcribe_audio(
                        audio_path=audio_path,
                        language="auto",
                        use_itn=True,
                        ban_emo_unk=False,
                        output_timestamp=False
                    )
                    f_out.write(transcription + "\n")
                    print(f"    âœ… ç›´æ¥è½¬å½•æˆåŠŸ: {folder}")
                    
                else:  # è¶…è¿‡3åˆ†é’Ÿä½¿ç”¨åˆ†æ®µè½¬å½•
                    print(f"    ğŸ¯ ä½¿ç”¨åˆ†æ®µè½¬å½•æ¨¡å¼ï¼ˆï¼3åˆ†é’Ÿï¼‰")
                    result = pipeline.transcribe_long_audio_simple(
                        audio_path=audio_path,
                        chunk_duration=60,  # æ¯æ®µ60ç§’
                        language="auto",
                        use_itn=True
                    )
                    
                    if result['full_text']:
                        f_out.write(result['full_text'] + "\n")
                        print(f"    âœ… åˆ†æ®µè½¬å½•æˆåŠŸ: {folder} (æˆåŠŸ{result['successful_chunks']}/{result['total_chunks']}ä¸ªç‰‡æ®µ)")
                    else:
                        error_msg = f"[ERROR] åˆ†æ®µè½¬å½•å¤±è´¥ï¼Œæ‰€æœ‰ç‰‡æ®µå‡æœªæˆåŠŸ\n"
                        f_out.write(error_msg)
                        print(f"    âŒ åˆ†æ®µè½¬å½•å¤±è´¥: {folder}")
                        
            except Exception as e:
                error_msg = f"[ERROR] å¤„ç†å¤±è´¥: {str(e)}\n"
                print(f"âŒ å¤±è´¥: {folder} - {e}")
                f_out.write(error_msg)

    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼æ¯ä¸ª TPO æ–‡ä»¶å¤¹ä¸‹å·²ç”Ÿæˆ listening.txt")


def get_audio_duration(audio_path):
    """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        # ä½¿ç”¨librosaè·å–éŸ³é¢‘æ—¶é•¿
        y, sr = librosa.load(audio_path, sr=None, mono=True)
        duration = len(y) / sr
        return duration
    except Exception as e:
        print(f"    âš ï¸  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {e}")
        # å¦‚æœæ— æ³•è·å–æ—¶é•¿ï¼Œæ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—
        file_size = os.path.getsize(audio_path)
        # å‡è®¾æ˜¯å‹ç¼©éŸ³é¢‘ï¼Œå¤§è‡´ä¼°ç®—ï¼ˆè¿™ä¸ªä¼°ç®—å¯èƒ½ä¸å‡†ç¡®ï¼Œä½†ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼‰
        estimated_duration = file_size / (16 * 1024)  # ç²—ç•¥ä¼°ç®—
        print(f"    ğŸ“Š ä½¿ç”¨ä¼°ç®—æ—¶é•¿: {estimated_duration:.1f}ç§’")
        return estimated_duration


def main_with_progress():
    """å¸¦è¿›åº¦æ˜¾ç¤ºå’Œæ—¶é•¿æ£€æµ‹çš„ç‰ˆæœ¬"""
    base_dir = "data/task4"
    tpo_folders = [f"TPO{i}" for i in range(55, 76)]  # TPO66 åˆ° TPO75
    
    # åˆå§‹åŒ–è½¬å†™å™¨
    pipeline = VoiceTranscriptionPipeline()
    
    total = len(tpo_folders)
    success_count = 0
    fail_count = 0
    direct_count = 0
    segmented_count = 0
    
    print(f"ğŸ¯ å¼€å§‹å¤„ç† {total} ä¸ªTPOæ–‡ä»¶å¤¹...")
    
    for i, folder in enumerate(tpo_folders, 1):
        folder_path = os.path.join(base_dir, folder)
        if not os.path.isdir(folder_path):
            print(f"[{i}/{total}] âš ï¸  è·³è¿‡ï¼ˆæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼‰: {folder}")
            fail_count += 1
            continue

        # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
        audio_path = None
        for ext in [".m4a", ".mp3"]:
            candidate = os.path.join(folder_path, f"audio{ext}")
            if os.path.isfile(candidate):
                audio_path = candidate
                break

        output_path = os.path.join(folder_path, "listening.txt")

        with open(output_path, "w", encoding="utf-8") as f_out:
            if not audio_path:
                msg = "[ERROR] æœªæ‰¾åˆ° audio.m4a æˆ– audio.mp3\n"
                print(f"[{i}/{total}] âŒ {folder}: éŸ³é¢‘ç¼ºå¤±")
                f_out.write(msg)
                fail_count += 1
                continue

            print(f"[{i}/{total}] ğŸ”Š æ­£åœ¨å¤„ç†: {folder}")
            
            try:
                # è·å–éŸ³é¢‘æ—¶é•¿
                duration = get_audio_duration(audio_path)
                minutes = duration / 60
                print(f"    â±ï¸  éŸ³é¢‘æ—¶é•¿: {duration:.1f}ç§’ ({minutes:.1f}åˆ†é’Ÿ)")
                
                # ä»¥3åˆ†é’Ÿä¸ºåˆ†å‰²ç‚¹è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
                if duration <= 180:  # 3åˆ†é’ŸåŠä»¥ä¸‹
                    print("    ğŸ¯ ä½¿ç”¨ç›´æ¥è½¬å½•æ¨¡å¼ï¼ˆâ‰¤3åˆ†é’Ÿï¼‰")
                    transcription = pipeline.transcribe_audio(
                        audio_path=audio_path,
                        language="auto",
                        use_itn=True,
                        ban_emo_unk=False,
                        output_timestamp=False
                    )
                    f_out.write(transcription + "\n")
                    print(f"    âœ… ç›´æ¥è½¬å½•æˆåŠŸ")
                    success_count += 1
                    direct_count += 1
                    
                else:  # è¶…è¿‡3åˆ†é’Ÿ
                    print(f"    ğŸ¯ ä½¿ç”¨åˆ†æ®µè½¬å½•æ¨¡å¼ï¼ˆï¼3åˆ†é’Ÿï¼‰")
                    # æ ¹æ®æ—¶é•¿åŠ¨æ€è°ƒæ•´åˆ†å—å¤§å°
                    if duration > 600:  # è¶…è¿‡10åˆ†é’Ÿï¼Œä½¿ç”¨æ›´å°çš„åˆ†å—
                        chunk_duration = 45
                        print(f"    ğŸ”§ é•¿éŸ³é¢‘æ£€æµ‹ï¼Œä½¿ç”¨åˆ†å—å¤§å°: {chunk_duration}ç§’")
                    else:
                        chunk_duration = 60
                    
                    result = pipeline.transcribe_long_audio_simple(
                        audio_path=audio_path,
                        chunk_duration=chunk_duration,
                        language="auto",
                        use_itn=True
                    )
                    
                    if result['full_text']:
                        f_out.write(result['full_text'] + "\n")
                        print(f"    âœ… åˆ†æ®µè½¬å½•æˆåŠŸ (æˆåŠŸ{result['successful_chunks']}/{result['total_chunks']}ä¸ªç‰‡æ®µ)")
                        success_count += 1
                        segmented_count += 1
                    else:
                        error_msg = f"[ERROR] åˆ†æ®µè½¬å½•å¤±è´¥\n"
                        f_out.write(error_msg)
                        print(f"    âŒ åˆ†æ®µè½¬å½•å¤±è´¥")
                        fail_count += 1
                            
            except Exception as e:
                error_msg = f"[ERROR] å¤„ç†å¤±è´¥: {str(e)}\n"
                print(f"    âŒ å¤±è´¥: {e}")
                f_out.write(error_msg)
                fail_count += 1

    print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {success_count}/{total}")
    print(f"   å¤±è´¥: {fail_count}/{total}")
    print(f"   ç›´æ¥è½¬å½•: {direct_count} ä¸ª")
    print(f"   åˆ†æ®µè½¬å½•: {segmented_count} ä¸ª")


if __name__ == "__main__":
    # ä½¿ç”¨å¸¦è¿›åº¦æ˜¾ç¤ºçš„ç‰ˆæœ¬
    main_with_progress()